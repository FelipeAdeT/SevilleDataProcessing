{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the results of Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of training (and its evaluation) will depend on how the data was split into training and testing sets. In this worksheet, we use repeated random subsampling to assess the performance of our trained model.\n",
    "\n",
    "According to [Wikipedia](https://en.wikipedia.org/wiki/Cross-validation_(statistics)):\n",
    "\n",
    ">This method, also known as Monte Carlo cross-validation,[16] creates multiple random splits of the dataset into training and validation data.[17] For each such split, the model is fit to the training data, and predictive accuracy is assessed using the validation data. The results are then averaged over the splits. The advantage of this method (over k-fold cross validation) is that the proportion of the training/validation split is not dependent on the number of iterations (folds). The disadvantage of this method is that some observations may never be selected in the validation subsample, whereas others may be selected more than once. In other words, validation subsets may overlap. This method also exhibits Monte Carlo variation, meaning that the results will vary if the analysis is repeated with different random splits.\n",
    "\n",
    "We will be dividing our data into an 80-20 split, using 80% for training and 20% for testing. This will be repeated randomly for each iteration of training to evaluate how much the training improves results on average.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary modules\n",
    "\n",
    "from __future__ import unicode_literals, print_function\n",
    "import spacy\n",
    "from spacy.lang.es import Spanish \n",
    "from spacy.scorer import Scorer\n",
    "from spacy.language import GoldParse\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import plac\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Tagged Data from JSON file\n",
    "with open('AMSTrainingII_SF.json', 'r', encoding='utf-8') as fp2:\n",
    "    TAGGED_DATA = json.load(fp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spacy has a built-in function for evaluating a model's performance using the [command line](https://spacy.io/api/cli#evaluate), but alternatively you can define a function like the one below. It takes the NER model and examples that you input and returns several metrics:\n",
    "        - UAS (Unlabelled Attachment Score) \n",
    "        - LAS (Labelled Attachment Score)\n",
    "        - ents_p\n",
    "        - ents_r\n",
    "        - ents_f\n",
    "        - tags_acc\n",
    "        - token_acc\n",
    "\n",
    "[According](https://github.com/explosion/spaCy/issues/2405) to one of the creators of Spacy, \n",
    ">The UAS and LAS are standard metrics to evaluate dependency parsing. UAS is the proportion of tokens whose head has been correctly assigned, LAS is the proportion of tokens whose head has been correctly assigned with the right dependency label (subject, object, etc).\n",
    ">ents_p, ents_r, ents_f are the precision, recall and fscore for the NER task.\n",
    ">tags_acc is the POS tagging accuracy.\n",
    ">token_acc seems to be the precision for token segmentation.\n",
    "\n",
    "The key metrics for this task are the precision, recall and f-score.\n",
    "**Precision** (ents_p) is the ratio of correctly-labeled entities out of all the entities labeled. (True Positive/(True Positive+False Positive)).\n",
    "**Recall**  (ents_r) is the ratio of correctly-labeled entities out of all true entities (True Positive/(True Positive+False Negative)). The F-score is the mean of both values.  \n",
    "\n",
    "These metrics all appear averaged out through all the entity types (labels) and then detailed for each label in particular. We want these values to be as close as possible to 100. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " def evaluate(ner_model, examples):\n",
    "        scorer = Scorer()\n",
    "        for sents, ents in examples:\n",
    "            doc_gold = ner_model.make_doc(sents)\n",
    "            gold = GoldParse(doc_gold, entities=ents['entities'])\n",
    "            pred_value = ner_model(sents)\n",
    "            scorer.score(pred_value, gold)\n",
    "        return scorer.scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load the Spacy model, define a blank dataframe to store the output of our different trials, and calculate the amount of data necessary for an 80-20 split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Spacy Model\n",
    "nlp= spacy.load('es_core_news_ml_EMS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a blank dataframe with columns for the information we are interested in\n",
    "\n",
    "columns=['ents_p', 'ents_r', 'ents_f', 'label']\n",
    "eval_data = pd.DataFrame(columns=columns)\n",
    "eval_data = eval_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate 80% of data for an 80-20 split\n",
    "\n",
    "len(TAGGED_DATA)*0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we run the training loop ten times, each with a different 80-20 split, and store the evaluation statistics of our NER model in our dataframe. We are using a copy of the NLP model because we want the training to start afresh for each set of training data. Otherwise, the model would be trained on all the data including the test data, leading to the model overperforming on the tagged data compared to new samples that we are interested in tagging later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Felipe/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (20000, 50))\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 3591.5471024410667}\n",
      "Losses {'ner': 2690.530075185315}\n",
      "Losses {'ner': 2293.0892819620667}\n",
      "Losses {'ner': 1998.821414852835}\n",
      "Losses {'ner': 1966.5152335241576}\n",
      "Losses {'ner': 1474.1909109121507}\n",
      "Losses {'ner': 1610.5948918567722}\n",
      "Losses {'ner': 1527.3823162800095}\n",
      "Losses {'ner': 1320.9996693693686}\n",
      "Losses {'ner': 1172.837904502785}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Felipe/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (20000, 50))\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 3173.365915730778}\n",
      "Losses {'ner': 2605.258725921552}\n",
      "Losses {'ner': 2231.7535603933584}\n",
      "Losses {'ner': 1894.8959838595767}\n",
      "Losses {'ner': 1740.9894983682075}\n",
      "Losses {'ner': 1921.943867120505}\n",
      "Losses {'ner': 1543.7140949294603}\n",
      "Losses {'ner': 1458.7159114796991}\n",
      "Losses {'ner': 1226.3817615201285}\n",
      "Losses {'ner': 1176.5516203799134}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Felipe/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (20000, 50))\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 3359.824695674141}\n",
      "Losses {'ner': 2371.2248234036533}\n",
      "Losses {'ner': 2034.2361413680435}\n",
      "Losses {'ner': 1972.2211253678627}\n",
      "Losses {'ner': 1749.111869845779}\n",
      "Losses {'ner': 1683.5968692939193}\n",
      "Losses {'ner': 1398.9753319906195}\n",
      "Losses {'ner': 1385.0082297985693}\n",
      "Losses {'ner': 1352.7585104838372}\n",
      "Losses {'ner': 1088.2770128995617}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Felipe/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (20000, 50))\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 3265.25447810646}\n",
      "Losses {'ner': 2355.0180194657164}\n",
      "Losses {'ner': 2167.2210276501687}\n",
      "Losses {'ner': 1874.0685026616434}\n",
      "Losses {'ner': 1795.589476999211}\n",
      "Losses {'ner': 1541.5740136824422}\n",
      "Losses {'ner': 1375.9743149334263}\n",
      "Losses {'ner': 1325.733408356837}\n",
      "Losses {'ner': 1224.5119927092956}\n",
      "Losses {'ner': 1147.1287610851045}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Felipe/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (20000, 50))\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 3765.1766208544823}\n",
      "Losses {'ner': 3027.056084658687}\n",
      "Losses {'ner': 2419.363837527841}\n",
      "Losses {'ner': 2007.044103132136}\n",
      "Losses {'ner': 1817.011837738826}\n",
      "Losses {'ner': 1721.18782892511}\n",
      "Losses {'ner': 1589.6306925566919}\n",
      "Losses {'ner': 1531.711822082291}\n",
      "Losses {'ner': 1281.9176980432537}\n",
      "Losses {'ner': 1278.0093234992353}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Felipe/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (20000, 50))\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 3047.6981249443556}\n",
      "Losses {'ner': 2595.772253100031}\n",
      "Losses {'ner': 2163.5630413808294}\n",
      "Losses {'ner': 2119.484450748131}\n",
      "Losses {'ner': 1772.286471196419}\n",
      "Losses {'ner': 1687.3062683072387}\n",
      "Losses {'ner': 1439.2444582623395}\n",
      "Losses {'ner': 1351.8477621278744}\n",
      "Losses {'ner': 1368.1221400195393}\n",
      "Losses {'ner': 1211.8483465643271}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Felipe/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (20000, 50))\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 3355.4537231886716}\n",
      "Losses {'ner': 2579.0712716618573}\n",
      "Losses {'ner': 2425.906617046779}\n",
      "Losses {'ner': 1914.988882358907}\n",
      "Losses {'ner': 1801.8912939606005}\n",
      "Losses {'ner': 1682.313634275592}\n",
      "Losses {'ner': 1554.5427463052836}\n",
      "Losses {'ner': 1551.337292174777}\n",
      "Losses {'ner': 1241.3630930274228}\n",
      "Losses {'ner': 1162.6659162593583}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Felipe/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (20000, 50))\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 3394.151698168256}\n",
      "Losses {'ner': 2376.498884129312}\n",
      "Losses {'ner': 2014.6121001837673}\n",
      "Losses {'ner': 1900.183606063558}\n",
      "Losses {'ner': 1804.73077124402}\n",
      "Losses {'ner': 1726.4452650258775}\n",
      "Losses {'ner': 1592.774578937139}\n",
      "Losses {'ner': 1467.208908037217}\n",
      "Losses {'ner': 1536.8202473560439}\n",
      "Losses {'ner': 1327.6897618564385}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Felipe/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (20000, 50))\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 3201.4267012121404}\n",
      "Losses {'ner': 2396.6217873936653}\n",
      "Losses {'ner': 2140.1321836786483}\n",
      "Losses {'ner': 1872.5953236758367}\n",
      "Losses {'ner': 1751.68427697363}\n",
      "Losses {'ner': 1746.491105319234}\n",
      "Losses {'ner': 1636.3151750145018}\n",
      "Losses {'ner': 1565.267411978829}\n",
      "Losses {'ner': 1443.6309273053087}\n",
      "Losses {'ner': 1404.0486455916766}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Felipe/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (20000, 50))\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 3736.4065660341425}\n",
      "Losses {'ner': 2602.4843297683783}\n",
      "Losses {'ner': 2345.6740134651104}\n",
      "Losses {'ner': 1967.469838794346}\n",
      "Losses {'ner': 1969.1729780225508}\n",
      "Losses {'ner': 1765.7099652288762}\n",
      "Losses {'ner': 1623.769290027325}\n",
      "Losses {'ner': 1400.5577166877981}\n",
      "Losses {'ner': 1322.8651575191518}\n",
      "Losses {'ner': 1334.4372154311782}\n"
     ]
    }
   ],
   "source": [
    "# Testing how much the evaluation depends on texts included in testing data\n",
    "\n",
    "#Loop 10 times\n",
    "for x in range(0,10):\n",
    "    \n",
    "    #Batching the Tagged Data into training and evaluation data (80-20 split)\n",
    "\n",
    "    random.shuffle(TAGGED_DATA)\n",
    "    train_data = TAGGED_DATA[:326]\n",
    "    test_data = TAGGED_DATA[326:]\n",
    "\n",
    "    #Load the model to be trained (save separately, because we do not want to repeatedly retrain the same model)\n",
    "    nlp1 = deepcopy(nlp)\n",
    "    \n",
    "    #Create object for retrieving the NER pipeline component\n",
    "    ner=nlp1.get_pipe(\"ner\")\n",
    "\n",
    "    #Generate new labels for the NER component (if you wish to create new labels)\n",
    "    #ner.add_label(\"MON\")\n",
    "    #ner.add_label(\"MON\")\n",
    "    #ner.add_label(\"DATE\")\n",
    "\n",
    "    #This piece of code creates a loop in which we train the model, but only for the NER component (disabling the tagger and the parser, which we are not using here).\n",
    "    with nlp1.disable_pipes('tagger','parser'):\n",
    "    #Here we resume training, alternatively you could begin_training if you are starting on a new model.\n",
    "        optimizer= nlp1.resume_training()\n",
    "    #Would need to figure this out, they are the sizes for the minibatching\n",
    "        sizes = compounding(1.0, 4.0, 1.001)\n",
    "    #This loops the training mechanism 10 times, randomly shuffling the training data and creating mini-batches from which the algorithm learns to label. Each time a batch is processed, the model is updated.\n",
    "        for itn in range(10):\n",
    "            random.shuffle(train_data)\n",
    "            batches = minibatch(train_data, size=sizes)\n",
    "            losses = {}\n",
    "            for batch in batches:\n",
    "                texts, annotations = zip(*batch)\n",
    "                nlp1.update(texts, annotations, sgd=optimizer, drop=0.35, losses=losses)\n",
    "            print(\"Losses\", losses)\n",
    "    \n",
    "    #Testing NER results of existing model on test data\n",
    "\n",
    "    results = evaluate(nlp1,test_data)\n",
    "    evaluation= dict((k, results[k]) for k in ['ents_per_type'] \n",
    "                                        if k in results)\n",
    "    \n",
    "    ev_date = [val.get('DATE') for val in evaluation.values()]\n",
    "    ev_mon= [val.get('MON') for val in evaluation.values()]\n",
    "    #ev_obj= [val.get('OBJ') for val in evaluation.values()]\n",
    "    ev_org= [val.get('ORG') for val in evaluation.values()]\n",
    "    ev_per= [val.get('PER') for val in evaluation.values()]\n",
    "    ev_loc= [val.get('LOC') for val in evaluation.values()]\n",
    "    \n",
    "    dlist = list(ev_date[0].values())\n",
    "    newrow1= {'ents_p': dlist[0],'ents_r': dlist[1],'ents_f':dlist[2],'label':'DATE'}\n",
    "    \n",
    "    mlist = list(ev_mon[0].values())\n",
    "    newrow2= {'ents_p': mlist[0],'ents_r':mlist[1],'ents_f':mlist[2],'label':'MON'}\n",
    "                  \n",
    "    #oblist = list(ev_obj[0].values())\n",
    "    #newrow3= {'ents_p':oblist[0],'ents_r':oblist[1],'ents_f':oblist[2],'label':'OBJ'}\n",
    "                  \n",
    "    orlist = list(ev_org[0].values())\n",
    "    newrow4= {'ents_p':orlist[0],'ents_r':orlist[1],'ents_f':orlist[2],'label':'ORG'}\n",
    "                  \n",
    "    plist = list(ev_per[0].values())\n",
    "    newrow5= {'ents_p':plist[0],'ents_r':plist[1],'ents_f':plist[2],'label':'PER'}\n",
    "                  \n",
    "    llist = list(ev_loc[0].values())\n",
    "    newrow6= {'ents_p':llist[0],'ents_r':llist[1],'ents_f':llist[2],'label':'LOC'}\n",
    "                  \n",
    "    eval_data=eval_data.append(newrow1,ignore_index=True)\n",
    "    eval_data=eval_data.append(newrow2,ignore_index=True)\n",
    "    #eval_data=eval_data.append(newrow3,ignore_index=True)\n",
    "    eval_data=eval_data.append(newrow4,ignore_index=True)\n",
    "    eval_data=eval_data.append(newrow5,ignore_index=True)\n",
    "    eval_data=eval_data.append(newrow6,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we print the contents of our evaluation dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ents_p     ents_r     ents_f label\n",
      "0   81.651376  81.651376  81.651376  DATE\n",
      "1   87.577640  87.577640  87.577640   MON\n",
      "2   62.962963  65.891473  64.393939   ORG\n",
      "3   92.446043  92.446043  92.446043   PER\n",
      "4   89.772727  80.338983  84.794275   LOC\n",
      "5   85.046729  81.250000  83.105023  DATE\n",
      "6   82.758621  90.225564  86.330935   MON\n",
      "7   70.588235  60.000000  64.864865   ORG\n",
      "8   91.544118  90.710383  91.125343   PER\n",
      "9   86.111111  88.888889  87.477954   LOC\n",
      "10  81.415929  83.636364  82.511211  DATE\n",
      "11  87.150838  88.636364  87.887324   MON\n",
      "12  68.421053  53.719008  60.185185   ORG\n",
      "13  91.218638  93.223443  92.210145   PER\n",
      "14  85.559567  88.104089  86.813187   LOC\n",
      "15  88.392857  83.193277  85.714286  DATE\n",
      "16  61.637931  89.375000  72.959184   MON\n",
      "17  70.476190  73.267327  71.844660   ORG\n",
      "18  92.816635  93.702290  93.257360   PER\n",
      "19  90.573770  87.007874  88.755020   LOC\n",
      "20  82.178218  82.178218  82.178218  DATE\n",
      "21  91.709845  93.650794  92.670157   MON\n",
      "22  62.280702  62.280702  62.280702   ORG\n",
      "23  93.884892  93.548387  93.716338   PER\n",
      "24  94.071146  85.920578  89.811321   LOC\n",
      "25  82.456140  83.928571  83.185841  DATE\n",
      "26  64.426877  90.055249  75.115207   MON\n",
      "27  67.346939  60.000000  63.461538   ORG\n",
      "28  92.529711  93.162393  92.844974   PER\n",
      "29  88.888889  82.666667  85.664940   LOC\n",
      "30  88.181818  87.387387  87.782805  DATE\n",
      "31  63.876652  94.771242  76.315789   MON\n",
      "32  54.761905  51.879699  53.281853   ORG\n",
      "33  94.363636  94.363636  94.363636   PER\n",
      "34  89.036545  85.350318  87.154472   LOC\n",
      "35  84.090909  74.747475  79.144385  DATE\n",
      "36  86.263736  85.792350  86.027397   MON\n",
      "37  72.727273  59.701493  65.573770   ORG\n",
      "38  95.353160  90.636042  92.934783   PER\n",
      "39  88.153310  85.762712  86.941581   LOC\n",
      "40  89.690722  87.000000  88.324873  DATE\n",
      "41  90.751445  93.452381  92.082111   MON\n",
      "42  61.666667  60.655738  61.157025   ORG\n",
      "43  90.744102  90.415913  90.579710   PER\n",
      "44  85.660377  86.311787  85.984848   LOC\n",
      "45  83.333333  73.529412  78.125000  DATE\n",
      "46  83.125000  93.006993  87.788779   MON\n",
      "47  62.921348  59.574468  61.202186   ORG\n",
      "48  93.478261  93.849206  93.663366   PER\n",
      "49  89.716312  91.335740  90.518784   LOC\n"
     ]
    }
   ],
   "source": [
    "print(eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Measure mean and standard deviation of f, p and r scores for each label \n",
    "a = eval_data.groupby('label').agg({'ents_f':['mean','std'],'ents_p':['mean','std'],'ents_r':['mean','std']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">ents_f</th>\n",
       "      <th colspan=\"2\" halign=\"left\">ents_p</th>\n",
       "      <th colspan=\"2\" halign=\"left\">ents_r</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <td>83.172302</td>\n",
       "      <td>3.328496</td>\n",
       "      <td>84.643803</td>\n",
       "      <td>3.063558</td>\n",
       "      <td>81.850208</td>\n",
       "      <td>4.554440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOC</th>\n",
       "      <td>87.391638</td>\n",
       "      <td>1.819658</td>\n",
       "      <td>88.754376</td>\n",
       "      <td>2.598420</td>\n",
       "      <td>86.168764</td>\n",
       "      <td>3.086064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MON</th>\n",
       "      <td>84.475452</td>\n",
       "      <td>7.070495</td>\n",
       "      <td>79.927858</td>\n",
       "      <td>11.820308</td>\n",
       "      <td>90.654358</td>\n",
       "      <td>2.956130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORG</th>\n",
       "      <td>62.824572</td>\n",
       "      <td>4.710390</td>\n",
       "      <td>65.415327</td>\n",
       "      <td>5.459031</td>\n",
       "      <td>60.696991</td>\n",
       "      <td>5.936379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PER</th>\n",
       "      <td>92.714170</td>\n",
       "      <td>1.173462</td>\n",
       "      <td>92.837920</td>\n",
       "      <td>1.456385</td>\n",
       "      <td>92.605774</td>\n",
       "      <td>1.479931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ents_f               ents_p                ents_r          \n",
       "            mean       std       mean        std       mean       std\n",
       "label                                                                \n",
       "DATE   83.172302  3.328496  84.643803   3.063558  81.850208  4.554440\n",
       "LOC    87.391638  1.819658  88.754376   2.598420  86.168764  3.086064\n",
       "MON    84.475452  7.070495  79.927858  11.820308  90.654358  2.956130\n",
       "ORG    62.824572  4.710390  65.415327   5.459031  60.696991  5.936379\n",
       "PER    92.714170  1.173462  92.837920   1.456385  92.605774  1.479931"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Evaluating Spelling Normalization\n",
    "\n",
    "We can apply the evaluation above to a model trained with text whose spelling has been normalized, thus evaluating whether the inclusion of a normalization dictionary improves training results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Norm Exceptions from JSON file\n",
    "with open('normalizeddict.json', 'r', encoding='utf-8') as fp3:\n",
    "    NORM_EXCEPTIONS = json.load(fp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define and add pipeline component that updates .norm attribute\n",
    "\n",
    "def add_custom_norms(doc):\n",
    "    for token in doc:\n",
    "        if token.text in NORM_EXCEPTIONS:\n",
    "            token.norm_ = NORM_EXCEPTIONS[token.text]\n",
    "    return doc\n",
    "\n",
    "#Add component to the pipeline\n",
    "\n",
    "nlp.add_pipe(add_custom_norms, first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a new blank dataframe with columns for the information we are interested in\n",
    "\n",
    "columns=['ents_p', 'ents_r', 'ents_f', 'label']\n",
    "eval_data2 = pd.DataFrame(columns=columns)\n",
    "eval_data2 = eval_data2.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Felipe/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (20000, 50))\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 29499.62115381894}\n",
      "Losses {'ner': 27432.198336651258}\n",
      "Losses {'ner': 27237.476574885826}\n",
      "Losses {'ner': 26886.309408007888}\n",
      "Losses {'ner': 26540.757857780347}\n",
      "Losses {'ner': 26545.37359688431}\n",
      "Losses {'ner': 26574.1013068147}\n",
      "Losses {'ner': 26679.740034505725}\n",
      "Losses {'ner': 26516.571289405227}\n",
      "Losses {'ner': 26684.599556565285}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Felipe/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (20000, 50))\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 30651.302070253238}\n",
      "Losses {'ner': 28284.725300171824}\n",
      "Losses {'ner': 27811.04373792749}\n",
      "Losses {'ner': 27858.08806299469}\n",
      "Losses {'ner': 27718.562570926966}\n",
      "Losses {'ner': 27328.900965396315}\n",
      "Losses {'ner': 27189.881448478438}\n",
      "Losses {'ner': 27317.36295453459}\n",
      "Losses {'ner': 27218.52796754241}\n",
      "Losses {'ner': 27065.22095376253}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Felipe/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (20000, 50))\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 29590.74765747037}\n",
      "Losses {'ner': 27184.64154662579}\n",
      "Losses {'ner': 27026.793694191245}\n",
      "Losses {'ner': 26454.55213338224}\n",
      "Losses {'ner': 26839.336028540452}\n",
      "Losses {'ner': 26708.574336301535}\n",
      "Losses {'ner': 26650.113122107927}\n",
      "Losses {'ner': 26635.132207155228}\n",
      "Losses {'ner': 26199.49300429225}\n",
      "Losses {'ner': 26226.21255362034}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Felipe/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (20000, 50))\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 28093.531449958275}\n",
      "Losses {'ner': 25667.964437861654}\n",
      "Losses {'ner': 24951.78715877945}\n",
      "Losses {'ner': 25100.753037386166}\n",
      "Losses {'ner': 24785.410763391832}\n",
      "Losses {'ner': 24760.63866879698}\n",
      "Losses {'ner': 24289.866849032464}\n",
      "Losses {'ner': 24400.87175379321}\n",
      "Losses {'ner': 24482.260458946228}\n",
      "Losses {'ner': 24565.933971002698}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Felipe/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (20000, 50))\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 28332.016745980498}\n",
      "Losses {'ner': 26362.2281262184}\n",
      "Losses {'ner': 25635.542517440506}\n",
      "Losses {'ner': 25117.322425551873}\n",
      "Losses {'ner': 25136.405352118192}\n",
      "Losses {'ner': 25244.448437670246}\n",
      "Losses {'ner': 24999.708883602172}\n",
      "Losses {'ner': 25051.532636642456}\n",
      "Losses {'ner': 24823.247329860926}\n",
      "Losses {'ner': 24896.657667689025}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Felipe/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (20000, 50))\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 28390.664817206565}\n",
      "Losses {'ner': 26001.15853855208}\n",
      "Losses {'ner': 25853.95808242492}\n",
      "Losses {'ner': 25646.67148854825}\n",
      "Losses {'ner': 25621.01740635198}\n",
      "Losses {'ner': 25310.714385457337}\n",
      "Losses {'ner': 25641.85621431656}\n",
      "Losses {'ner': 25141.601619463414}\n",
      "Losses {'ner': 25471.13282689452}\n",
      "Losses {'ner': 25402.038847267628}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Felipe/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (20000, 50))\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 28857.829207675437}\n",
      "Losses {'ner': 26427.575190555293}\n",
      "Losses {'ner': 25773.047303230134}\n",
      "Losses {'ner': 25860.04211168643}\n",
      "Losses {'ner': 25870.547863037034}\n",
      "Losses {'ner': 25445.04180361796}\n",
      "Losses {'ner': 25652.979458531365}\n",
      "Losses {'ner': 25652.355613194406}\n",
      "Losses {'ner': 25368.51256494224}\n",
      "Losses {'ner': 25482.41212736629}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Felipe/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (20000, 50))\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 31183.07043193781}\n",
      "Losses {'ner': 28938.966911083655}\n",
      "Losses {'ner': 28314.097444169314}\n",
      "Losses {'ner': 27981.325828345012}\n",
      "Losses {'ner': 27896.63830166764}\n",
      "Losses {'ner': 27506.291575556505}\n",
      "Losses {'ner': 27805.07676478289}\n",
      "Losses {'ner': 27623.085354603827}\n",
      "Losses {'ner': 27410.957109078765}\n",
      "Losses {'ner': 27565.289154559374}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Felipe/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (20000, 50))\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 29698.50474952518}\n",
      "Losses {'ner': 28100.42544671885}\n",
      "Losses {'ner': 27684.143731447766}\n",
      "Losses {'ner': 27413.299044790547}\n",
      "Losses {'ner': 27221.78061976153}\n",
      "Losses {'ner': 27076.371534661856}\n",
      "Losses {'ner': 26987.433071333915}\n",
      "Losses {'ner': 27206.584793627262}\n",
      "Losses {'ner': 26959.954725861317}\n",
      "Losses {'ner': 27405.67962694168}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Felipe/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (20000, 50))\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 27282.973104532}\n",
      "Losses {'ner': 25546.693975118553}\n",
      "Losses {'ner': 24631.723043808382}\n",
      "Losses {'ner': 24399.073844784987}\n",
      "Losses {'ner': 24632.41723647827}\n",
      "Losses {'ner': 24773.259103098884}\n",
      "Losses {'ner': 24214.003735827282}\n",
      "Losses {'ner': 24327.542434114963}\n",
      "Losses {'ner': 23951.511757960543}\n",
      "Losses {'ner': 24057.59735112358}\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate Model trained with EMS dictionary\n",
    "\n",
    "#Loop 10 times\n",
    "for x in range(0,10):\n",
    "    \n",
    "    random.shuffle(TAGGED_DATA)\n",
    "    train_data = TAGGED_DATA[:326]\n",
    "    test_data = TAGGED_DATA[326:]\n",
    "    \n",
    "    #Load the model to be trained\n",
    "    nlp2 = deepcopy(nlp)\n",
    "    \n",
    "    #Create object for retrieving the NER pipeline component\n",
    "    ner=nlp2.get_pipe(\"ner\")\n",
    "\n",
    "    #Generate new labels for the NER component (if you wish to create new labels)\n",
    "    ner.add_label(\"OBJ\")\n",
    "    ner.add_label(\"MON\")\n",
    "    ner.add_label(\"DATE\")\n",
    "\n",
    "    #This piece of code creates a loop in which we train the model, but only for the NER component (disabling the tagger and the parser, which we are not using here).\n",
    "    with nlp2.disable_pipes('tagger','parser'):\n",
    "    #Here we resume training, alternatively you could begin_training if you are starting on a new model.\n",
    "        optimizer= nlp2.resume_training()\n",
    "    #Would need to figure this out, they are the sizes for the minibatching\n",
    "        sizes = compounding(1.0, 4.0, 1.001)\n",
    "    #This loops the training mechanism 10 times, randomly shuffling the training data and creating mini-batches from which the algorithm learns to label. Each time a batch is processed, the model is updated.\n",
    "        for itn in range(10):\n",
    "            random.shuffle(train_data)\n",
    "            batches = minibatch(train_data, size=sizes)\n",
    "            losses = {}\n",
    "            for batch in batches:\n",
    "                texts, annotations = zip(*batch)\n",
    "                nlp2.update(texts, annotations, sgd=optimizer, drop=0.35, losses=losses)\n",
    "            print(\"Losses\", losses)\n",
    "   \n",
    " #Testing NER results of existing model on test data\n",
    "\n",
    "    results = evaluate(nlp2,test_data)\n",
    "    evaluation= dict((k, results[k]) for k in ['ents_per_type'] \n",
    "                                        if k in results)\n",
    "    \n",
    "    ev_date = [val.get('DATE') for val in evaluation.values()]\n",
    "    ev_mon= [val.get('MON') for val in evaluation.values()]\n",
    "    ev_obj= [val.get('OBJ') for val in evaluation.values()]\n",
    "    ev_org= [val.get('ORG') for val in evaluation.values()]\n",
    "    ev_per= [val.get('PER') for val in evaluation.values()]\n",
    "    ev_loc= [val.get('LOC') for val in evaluation.values()]\n",
    "    \n",
    "    dlist = list(ev_date[0].values())\n",
    "    newrow1= {'ents_p': dlist[0],'ents_r': dlist[1],'ents_f':dlist[2],'label':'DATE'}\n",
    "    \n",
    "    mlist = list(ev_mon[0].values())\n",
    "    newrow2= {'ents_p': mlist[0],'ents_r':mlist[1],'ents_f':mlist[2],'label':'MON'}\n",
    "                  \n",
    "    oblist = list(ev_obj[0].values())\n",
    "    newrow3= {'ents_p':oblist[0],'ents_r':oblist[1],'ents_f':oblist[2],'label':'OBJ'}\n",
    "                  \n",
    "    orlist = list(ev_org[0].values())\n",
    "    newrow4= {'ents_p':orlist[0],'ents_r':orlist[1],'ents_f':orlist[2],'label':'ORG'}\n",
    "                  \n",
    "    plist = list(ev_per[0].values())\n",
    "    newrow5= {'ents_p':plist[0],'ents_r':plist[1],'ents_f':plist[2],'label':'PER'}\n",
    "                  \n",
    "    llist = list(ev_loc[0].values())\n",
    "    newrow6= {'ents_p':llist[0],'ents_r':llist[1],'ents_f':llist[2],'label':'LOC'}\n",
    "                  \n",
    "    eval_data2=eval_data2.append(newrow1,ignore_index=True)\n",
    "    eval_data2=eval_data2.append(newrow2,ignore_index=True)\n",
    "    eval_data2=eval_data2.append(newrow3,ignore_index=True)\n",
    "    eval_data2=eval_data2.append(newrow4,ignore_index=True)\n",
    "    eval_data2=eval_data2.append(newrow5,ignore_index=True)\n",
    "    eval_data2=eval_data2.append(newrow6,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "b= eval_data2.groupby('label').agg({'ents_f':['mean','std'],'ents_p':['mean','std'],'ents_r':['mean','std']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we print the statistics for the training with (b) and without (a) spelling normalization. As can be seen, there is a slight improvement on most measurements (as well as a reduction in variability) when we normalize spelling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">ents_f</th>\n",
       "      <th colspan=\"2\" halign=\"left\">ents_p</th>\n",
       "      <th colspan=\"2\" halign=\"left\">ents_r</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <td>9.782182</td>\n",
       "      <td>9.578643</td>\n",
       "      <td>41.666667</td>\n",
       "      <td>40.253824</td>\n",
       "      <td>5.821155</td>\n",
       "      <td>5.936515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOC</th>\n",
       "      <td>80.577654</td>\n",
       "      <td>3.017314</td>\n",
       "      <td>85.263570</td>\n",
       "      <td>4.642661</td>\n",
       "      <td>76.664881</td>\n",
       "      <td>4.973763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MON</th>\n",
       "      <td>55.384011</td>\n",
       "      <td>13.193679</td>\n",
       "      <td>65.566869</td>\n",
       "      <td>13.052479</td>\n",
       "      <td>48.752034</td>\n",
       "      <td>13.813612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OBJ</th>\n",
       "      <td>1.888861</td>\n",
       "      <td>4.417157</td>\n",
       "      <td>23.333333</td>\n",
       "      <td>41.722185</td>\n",
       "      <td>1.003731</td>\n",
       "      <td>2.375146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORG</th>\n",
       "      <td>22.120174</td>\n",
       "      <td>14.267794</td>\n",
       "      <td>32.923158</td>\n",
       "      <td>19.451804</td>\n",
       "      <td>16.979782</td>\n",
       "      <td>11.556657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PER</th>\n",
       "      <td>85.964481</td>\n",
       "      <td>2.293672</td>\n",
       "      <td>87.336613</td>\n",
       "      <td>2.670296</td>\n",
       "      <td>84.667080</td>\n",
       "      <td>2.563800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ents_f                ents_p                ents_r           \n",
       "            mean        std       mean        std       mean        std\n",
       "label                                                                  \n",
       "DATE    9.782182   9.578643  41.666667  40.253824   5.821155   5.936515\n",
       "LOC    80.577654   3.017314  85.263570   4.642661  76.664881   4.973763\n",
       "MON    55.384011  13.193679  65.566869  13.052479  48.752034  13.813612\n",
       "OBJ     1.888861   4.417157  23.333333  41.722185   1.003731   2.375146\n",
       "ORG    22.120174  14.267794  32.923158  19.451804  16.979782  11.556657\n",
       "PER    85.964481   2.293672  87.336613   2.670296  84.667080   2.563800"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">ents_f</th>\n",
       "      <th colspan=\"2\" halign=\"left\">ents_p</th>\n",
       "      <th colspan=\"2\" halign=\"left\">ents_r</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <td>6.181599</td>\n",
       "      <td>9.238110</td>\n",
       "      <td>21.666667</td>\n",
       "      <td>33.379598</td>\n",
       "      <td>3.616384</td>\n",
       "      <td>5.377218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOC</th>\n",
       "      <td>82.013233</td>\n",
       "      <td>2.651031</td>\n",
       "      <td>86.110284</td>\n",
       "      <td>4.359660</td>\n",
       "      <td>78.437365</td>\n",
       "      <td>3.290363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MON</th>\n",
       "      <td>51.947078</td>\n",
       "      <td>9.837542</td>\n",
       "      <td>70.758458</td>\n",
       "      <td>12.463683</td>\n",
       "      <td>42.015463</td>\n",
       "      <td>10.894793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OBJ</th>\n",
       "      <td>2.933807</td>\n",
       "      <td>2.513359</td>\n",
       "      <td>48.333333</td>\n",
       "      <td>41.163630</td>\n",
       "      <td>1.525103</td>\n",
       "      <td>1.316534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORG</th>\n",
       "      <td>22.247787</td>\n",
       "      <td>8.778882</td>\n",
       "      <td>31.986232</td>\n",
       "      <td>12.151958</td>\n",
       "      <td>17.145127</td>\n",
       "      <td>6.982109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PER</th>\n",
       "      <td>86.558603</td>\n",
       "      <td>2.209405</td>\n",
       "      <td>88.364413</td>\n",
       "      <td>2.650517</td>\n",
       "      <td>84.850763</td>\n",
       "      <td>2.290407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ents_f               ents_p                ents_r           \n",
       "            mean       std       mean        std       mean        std\n",
       "label                                                                 \n",
       "DATE    6.181599  9.238110  21.666667  33.379598   3.616384   5.377218\n",
       "LOC    82.013233  2.651031  86.110284   4.359660  78.437365   3.290363\n",
       "MON    51.947078  9.837542  70.758458  12.463683  42.015463  10.894793\n",
       "OBJ     2.933807  2.513359  48.333333  41.163630   1.525103   1.316534\n",
       "ORG    22.247787  8.778882  31.986232  12.151958  17.145127   6.982109\n",
       "PER    86.558603  2.209405  88.364413   2.650517  84.850763   2.290407"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
